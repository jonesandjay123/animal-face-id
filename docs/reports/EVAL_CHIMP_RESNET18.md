# ResNet-18 模型在 Chimp-min10 資料集上的訓練評估

這份報告分析了使用 ResNet-18 架構在 `chimp-min10` 資料集上進行訓練的效能指標。

## 訓練指標變化圖

![訓練指標變化圖](./chimp_resnet18_metrics.png)

上圖顯示了訓練和驗證過程中的損失 (Loss) 和 Top-1 準確率 (Top-1 Accuracy) 隨 epoch 的變化。

## 分析說明

### 1. 什麼時候開始進入 Plateau？

從圖中可以看出，模型的效能大約在 **Epoch 35-40** 之間開始進入高原期 (plateau)。

- **Validation Loss (驗證損失)**：在 Epoch 30 左右達到最低點，之後便開始回升，這表明模型從那時起開始失去泛化能力。
- **Validation Top-1 Accuracy (驗證準確率)**：在 Epoch 40 附近達到約 73% 的峰值，之後的增長非常緩慢，甚至略有下降，沒有明顯的提升。

綜合來看，模型的核心學習階段在 35 個 epoch 左右已經完成。

### 2. 有沒有明顯 Overfitting？

**有，非常明顯的 Overfitting (過擬合)**。

主要證據如下：
- **損失曲線分離**：從大約 Epoch 8 開始，訓練損失 (train_loss) 持續穩定下降並趨近於 0，但驗證損失 (val_loss) 在 Epoch 30 之後不降反升。這兩條曲線的巨大差距是過擬合的典型特徵。
- **準確率曲線分離**：訓練準確率 (train_top1) 很快達到了接近 100%，而驗證準確率 (val_top1) 卻停滯在 73% 左右。這表示模型完美地「記住」了訓練資料，但無法同樣好地應用於未見過的驗證資料。

### 3. 如果要再繼續訓練更久，效果大概會如何？

如果繼續訓練更久，**效果很可能會更差**。

基於目前的趨勢，可以預期：
- **過擬合會加劇**：`val_loss` 會持續上升，與 `train_loss` 的差距會越來越大。
- **泛化能力下降**：`val_top1` 不太可能再有顯著提升，反而有可能因為模型過度專注於訓練集的細節而開始下降。

因此，若要改善模型效果，不應只是增加訓練時間，而應考慮以下策略：
- 增強資料擴增 (Data Augmentation)。
- 加強正規化 (Regularization)，例如增加 Dropout 或權重衰減 (Weight Decay)。
- 採用 Early Stopping 策略，在 `val_loss` 開始上升時就停止訓練，以保存最佳的模型權重。
